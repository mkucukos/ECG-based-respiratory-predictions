{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e36834-a348-4d4d-a591-c381a27f48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32266271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'fantasia_dataset.plk'\n",
    "df = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b30c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by subject_id and choose one random subject\n",
    "grouped = df.groupby('subject_id')\n",
    "random_subject = np.random.choice(df['subject_id'].unique())\n",
    "\n",
    "# Filter the dataframe for the chosen subject\n",
    "subject_df = grouped.get_group(random_subject)\n",
    "\n",
    "# Convert samples to seconds\n",
    "sample_rate = 250  # 250 samples per second\n",
    "time_in_seconds = subject_df['sample'][1:7500] / sample_rate\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Plot ECG data\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time_in_seconds, subject_df['ecg'][1:7500], label='ECG', color='blue')\n",
    "plt.title(f'ECG and Respiration for Subject {random_subject}')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('ECG Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot respiration data\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time_in_seconds, subject_df['resp'][1:7500], label='Respiration', color='green')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Respiration Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb10390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Ensure the indices for slicing are within the bounds of the DataFrame\n",
    "sample_rate = 250  # 250 samples per second\n",
    "start_index = 1\n",
    "end_index = min(7500, len(subject_df))\n",
    "\n",
    "# Convert samples to seconds\n",
    "time_in_seconds = subject_df['sample'][start_index:end_index] / sample_rate\n",
    "\n",
    "# Respiration data for the selected range\n",
    "respiration = subject_df['resp'][start_index:end_index]\n",
    "\n",
    "# Clean and process the respiration data using nk.rsp_process\n",
    "rsp_signals, rsp_info = nk.rsp_process(subject_df['resp'], sampling_rate=sample_rate, method='khodadad2018')\n",
    "\n",
    "# Extract the cleaned respiration signal, peaks, troughs, and respiration rate\n",
    "cleaned_respiration = rsp_signals[\"RSP_Clean\"][start_index:end_index]\n",
    "peaks = rsp_signals[\"RSP_Peaks\"][start_index:end_index].values\n",
    "troughs = rsp_signals[\"RSP_Troughs\"][start_index:end_index].values\n",
    "respiration_rate = rsp_signals[\"RSP_Rate\"][start_index:end_index].values\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(3, 1, figsize=(14, 18))\n",
    "\n",
    "# Plot raw respiration data\n",
    "axs[0].plot(time_in_seconds, respiration, label='Raw Respiration', color='green', alpha=0.6)\n",
    "axs[0].set_title('Raw Respiration Data')\n",
    "axs[0].set_xlabel('Time (seconds)')\n",
    "axs[0].set_ylabel('Respiration Value')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot cleaned respiration data with peaks and troughs\n",
    "axs[1].plot(time_in_seconds, cleaned_respiration, label='Cleaned Respiration (NeuroKit)', color='black')\n",
    "axs[1].scatter(time_in_seconds[peaks == 1], cleaned_respiration[peaks == 1], color='red', marker='o', s=150, label='Peaks')\n",
    "axs[1].scatter(time_in_seconds[troughs == 1], cleaned_respiration[troughs == 1], color='blue', marker='o', s=150, label='Troughs')\n",
    "axs[1].set_title('Cleaned Respiration Data with Peaks and Troughs (Neurokit)')\n",
    "axs[1].set_xlabel('Time (seconds)')\n",
    "axs[1].set_ylabel('Respiration Value')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot respiration rate\n",
    "axs[2].plot(time_in_seconds, respiration_rate, label='Respiration Rate (Breaths per Minute)', color='purple', linestyle='--')\n",
    "axs[2].set_title('Respiration Rate')\n",
    "axs[2].set_xlabel('Time (seconds)')\n",
    "axs[2].set_ylabel('Breaths per Minute')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff08ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the indices for slicing are within the bounds of the DataFrame\n",
    "sample_rate = 250  # 250 samples per second\n",
    "start_index = 1\n",
    "end_index = min(7500, len(subject_df))\n",
    "\n",
    "# Convert samples to seconds\n",
    "time_in_seconds = subject_df['sample'][start_index:end_index] / sample_rate\n",
    "\n",
    "# Respiration data for the selected range\n",
    "respiration = subject_df['resp'][start_index:end_index]\n",
    "\n",
    "# Apply a low-pass Butterworth filter to the respiration data\n",
    "def low_pass_filter(data, cutoff_freq, sample_rate):\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(4, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "cutoff_frequency = 1  # Set the cutoff frequency to 1 Hz\n",
    "filtered_respiration = low_pass_filter(subject_df['resp'], cutoff_frequency, sample_rate)\n",
    "\n",
    "# Clean and process the filtered respiration data using nk.rsp_process\n",
    "rsp_signals, rsp_info = nk.rsp_process(filtered_respiration, sampling_rate=sample_rate, method='khodadad2018')\n",
    "\n",
    "# Extract the cleaned respiration signal, peaks, troughs, and respiration rate\n",
    "cleaned_respiration = rsp_signals[\"RSP_Clean\"][start_index:end_index]\n",
    "peaks = rsp_signals[\"RSP_Peaks\"][start_index:end_index].values\n",
    "troughs = rsp_signals[\"RSP_Troughs\"][start_index:end_index].values\n",
    "respiration_rate = rsp_signals[\"RSP_Rate\"][start_index:end_index].values\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(3, 1, figsize=(14, 18))\n",
    "\n",
    "# Plot raw respiration data\n",
    "axs[0].plot(time_in_seconds, respiration, label='Raw Respiration', color='green', alpha=0.6)\n",
    "axs[0].set_title('Raw Respiration Data')\n",
    "axs[0].set_xlabel('Time (seconds)')\n",
    "axs[0].set_ylabel('Respiration Value')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot cleaned respiration data with peaks and troughs\n",
    "axs[1].plot(time_in_seconds, cleaned_respiration, label='Cleaned Respiration (Butterworth + Neurokit)', color='black')\n",
    "axs[1].scatter(time_in_seconds[peaks == 1], cleaned_respiration[peaks == 1], color='red', marker='o', s=150, label='Peaks')\n",
    "axs[1].scatter(time_in_seconds[troughs == 1], cleaned_respiration[troughs == 1], color='blue', marker='o', s=150, label='Troughs')\n",
    "axs[1].set_title('Cleaned Respiration Data with Peaks and Troughs (Butterworth + Neurokit)')\n",
    "axs[1].set_xlabel('Time (seconds)')\n",
    "axs[1].set_ylabel('Respiration Value')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot respiration rate\n",
    "axs[2].plot(time_in_seconds, respiration_rate, label='Respiration Rate (Breaths per Minute)', color='purple', linestyle='--')\n",
    "axs[2].set_title('Respiration Rate')\n",
    "axs[2].set_xlabel('Time (seconds)')\n",
    "axs[2].set_ylabel('Breaths per Minute')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7561f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the indices for slicing are within the bounds of the DataFrame\n",
    "sample_rate = 250  # 250 samples per second\n",
    "start_index = 1\n",
    "end_index = min(7500, len(subject_df))\n",
    "\n",
    "# Convert samples to seconds\n",
    "time_in_seconds = subject_df['sample'][start_index:end_index] / sample_rate\n",
    "\n",
    "# Respiration data for the selected range\n",
    "respiration = subject_df['resp'][start_index:end_index]\n",
    "\n",
    "# Apply a low-pass Butterworth filter to the respiration data\n",
    "def low_pass_filter(data, cutoff_freq, sample_rate):\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(4, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "cutoff_frequency = 1  # Set the cutoff frequency to 1 Hz\n",
    "filtered_respiration = low_pass_filter(subject_df['resp'], cutoff_frequency, sample_rate)\n",
    "\n",
    "# Clean and process the filtered respiration data using nk.rsp_process\n",
    "rsp_signals, rsp_info = nk.rsp_process(filtered_respiration, sampling_rate=sample_rate, method='khodadad2018')\n",
    "\n",
    "# Extract the cleaned respiration signal, peaks, troughs, and respiration rate\n",
    "cleaned_respiration = rsp_signals[\"RSP_Clean\"][start_index:end_index]\n",
    "peaks = rsp_signals[\"RSP_Peaks\"][start_index:end_index].values\n",
    "troughs = rsp_signals[\"RSP_Troughs\"][start_index:end_index].values\n",
    "respiration_rate = rsp_signals[\"RSP_Rate\"][start_index:end_index].values\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(3, 1, figsize=(14, 18))\n",
    "\n",
    "# Plot raw respiration data\n",
    "axs[0].plot(time_in_seconds, respiration, label='Raw Respiration', color='green', alpha=0.6)\n",
    "axs[0].set_title('Raw Respiration Data')\n",
    "axs[0].set_xlabel('Time (seconds)')\n",
    "axs[0].set_ylabel('Respiration Value')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot cleaned respiration data with peaks and troughs\n",
    "axs[1].plot(time_in_seconds, cleaned_respiration, label='Cleaned Respiration (Butterworth + Neurokit)', color='black')\n",
    "axs[1].scatter(time_in_seconds[peaks == 1], cleaned_respiration[peaks == 1], color='red', marker='o', s=150, label='Peaks')\n",
    "axs[1].scatter(time_in_seconds[troughs == 1], cleaned_respiration[troughs == 1], color='blue', marker='o', s=150, label='Troughs')\n",
    "\n",
    "# Calculate and shade tidal volumes\n",
    "shaded_areas_peak_to_trough = []\n",
    "shaded_areas_trough_to_peak = []\n",
    "\n",
    "for i in range(1, len(peaks)):\n",
    "    if peaks[i] == 1 and i < len(troughs) - 1 and troughs[i] == 0:\n",
    "        # Shade area from peak to next trough\n",
    "        next_trough_idx = np.where(troughs[i:] == 1)[0]\n",
    "        if next_trough_idx.size > 0:\n",
    "            next_trough_idx = next_trough_idx[0] + i\n",
    "            axs[1].fill_between(time_in_seconds[i:next_trough_idx], 0, cleaned_respiration[i:next_trough_idx], color='lightblue', alpha=0.5)\n",
    "            area = np.trapz(cleaned_respiration[i:next_trough_idx], time_in_seconds[i:next_trough_idx])\n",
    "            shaded_areas_peak_to_trough.append(area)\n",
    "    elif troughs[i] == 1 and i < len(peaks) - 1 and peaks[i] == 0:\n",
    "        # Shade area from trough to next peak\n",
    "        next_peak_idx = np.where(peaks[i:] == 1)[0]\n",
    "        if next_peak_idx.size > 0:\n",
    "            next_peak_idx = next_peak_idx[0] + i\n",
    "            axs[1].fill_between(time_in_seconds[i:next_peak_idx], 0, cleaned_respiration[i:next_peak_idx], color='lightgreen', alpha=0.5)\n",
    "            area = np.trapz(cleaned_respiration[i:next_peak_idx], time_in_seconds[i:next_peak_idx])\n",
    "            shaded_areas_trough_to_peak.append(area)\n",
    "\n",
    "# Sum the absolute values of shaded areas\n",
    "sum_peak_to_trough = np.sum(np.abs(shaded_areas_peak_to_trough))\n",
    "sum_trough_to_peak = np.sum(np.abs(shaded_areas_trough_to_peak))\n",
    "\n",
    "# Display the sums as text in the second subplot\n",
    "textstr = '\\n'.join((\n",
    "    r'$\\sum_{peak \\rightarrow trough}=%.2f$' % (sum_peak_to_trough,),\n",
    "    r'$\\sum_{trough \\rightarrow peak}=%.2f$' % (sum_trough_to_peak,)\n",
    "))\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "axs[1].text(0.95, 0.05, textstr, transform=axs[1].transAxes, fontsize=14,\n",
    "            verticalalignment='bottom', horizontalalignment='right', bbox=props)\n",
    "\n",
    "axs[1].set_title('Cleaned Respiration Data with Peaks and Troughs (Butterworth + Neurokit)')\n",
    "axs[1].set_xlabel('Time (seconds)')\n",
    "axs[1].set_ylabel('Respiration Value')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Calculate and annotate the average respiration rate\n",
    "average_respiration_rate = np.mean(respiration_rate)\n",
    "textstr_rate = f'Average Respiration Rate: {average_respiration_rate:.2f} BPM'\n",
    "props_rate = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "axs[2].text(0.95, 0.05, textstr_rate, transform=axs[2].transAxes, fontsize=14,\n",
    "            verticalalignment='bottom', horizontalalignment='right', bbox=props_rate)\n",
    "\n",
    "# Plot respiration rate\n",
    "axs[2].plot(time_in_seconds, respiration_rate, label='Respiration Rate (Breaths per Minute)', color='purple', linestyle='--')\n",
    "axs[2].set_title('Respiration Rate')\n",
    "axs[2].set_xlabel('Time (seconds)')\n",
    "axs[2].set_ylabel('Breaths per Minute')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the shaded areas\n",
    "print(\"Shaded Areas from Peak to Next Trough:\", shaded_areas_peak_to_trough)\n",
    "print(\"Shaded Areas from Trough to Next Peak:\", shaded_areas_trough_to_peak)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_respiration_metrics(respiration_data, sample_rate=250, cutoff_frequency=1):\n",
    "    \"\"\"\n",
    "    Calculate respiration metrics including mean respiration rate, areas from peak to trough, and trough to peak.\n",
    "    \n",
    "    Args:\n",
    "    - respiration_data (array-like): The respiration signal data.\n",
    "    - sample_rate (int): The sampling rate of the data.\n",
    "    - cutoff_frequency (int): The cutoff frequency for the low-pass filter.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary containing mean respiration rate, areas from peak to trough, and trough to peak.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply low-pass Butterworth filter\n",
    "    def low_pass_filter(data, cutoff_freq, sample_rate):\n",
    "        nyquist = 0.5 * sample_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist\n",
    "        b, a = butter(4, normal_cutoff, btype='low', analog=False)\n",
    "        filtered_data = filtfilt(b, a, data)\n",
    "        return filtered_data\n",
    "\n",
    "    filtered_respiration = low_pass_filter(respiration_data, cutoff_frequency, sample_rate)\n",
    "\n",
    "    # Clean and process the filtered respiration data\n",
    "    rsp_signals, rsp_info = nk.rsp_process(filtered_respiration, sampling_rate=sample_rate, method='khodadad2018')\n",
    "    cleaned_respiration = rsp_signals[\"RSP_Clean\"]\n",
    "    peaks = rsp_signals[\"RSP_Peaks\"].values\n",
    "    troughs = rsp_signals[\"RSP_Troughs\"].values\n",
    "    respiration_rate = rsp_signals[\"RSP_Rate\"].values\n",
    "\n",
    "    # Calculate mean respiration rate\n",
    "    mean_respiration_rate = np.mean(respiration_rate)\n",
    "\n",
    "    # Calculate the areas for peak-to-trough and trough-to-peak transitions\n",
    "    shaded_areas_peak_to_trough = []\n",
    "    shaded_areas_trough_to_peak = []\n",
    "    \n",
    "    for i in range(1, len(cleaned_respiration)):\n",
    "        if peaks[i] == 1 and i < len(troughs) - 1:\n",
    "            # Find the next trough index after this peak\n",
    "            next_trough_idx = np.where(troughs[i:] == 1)[0]\n",
    "            if next_trough_idx.size > 0:\n",
    "                next_trough_idx = next_trough_idx[0] + i\n",
    "                area = np.trapz(cleaned_respiration[i:next_trough_idx], dx=1/sample_rate)\n",
    "                shaded_areas_peak_to_trough.append(area)\n",
    "        elif troughs[i] == 1 and i < len(peaks) - 1:\n",
    "            # Find the next peak index after this trough\n",
    "            next_peak_idx = np.where(peaks[i:] == 1)[0]\n",
    "            if next_peak_idx.size > 0:\n",
    "                next_peak_idx = next_peak_idx[0] + i\n",
    "                area = np.trapz(cleaned_respiration[i:next_peak_idx], dx=1/sample_rate)\n",
    "                shaded_areas_trough_to_peak.append(area)\n",
    "\n",
    "    sum_peak_to_trough = np.sum(np.abs(shaded_areas_peak_to_trough))\n",
    "    sum_trough_to_peak = np.sum(np.abs(shaded_areas_trough_to_peak))\n",
    "\n",
    "    # Return the calculated metrics\n",
    "    return {\n",
    "        \"Mean Respiration Rate\": mean_respiration_rate,\n",
    "        \"Total Area Peak to Trough\": sum_peak_to_trough,\n",
    "        \"Total Area Trough to Peak\": sum_trough_to_peak\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_respiration_metrics(subject_df['resp'][start_index:end_index],sample_rate=250, cutoff_frequency=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e802ad",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d059f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to split the data into chunks of a specified size\n",
    "def split_into_chunks(group, chunk_size=7500):\n",
    "    num_chunks = len(group) // chunk_size  # Calculate how many full chunks we can have\n",
    "    chunks = []\n",
    "    for i in range(num_chunks):\n",
    "        start = i * chunk_size\n",
    "        end = start + chunk_size\n",
    "        chunks.append({\n",
    "            'ecg': group['ecg'].iloc[start:end].tolist(),\n",
    "            'resp': group['resp'].iloc[start:end].tolist()\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "# Group the DataFrame by 'subject_id'\n",
    "grouped = df.groupby('subject_id')\n",
    "\n",
    "# Dictionary to hold the chunks for each subject\n",
    "subject_chunks = {}\n",
    "\n",
    "# Loop through each group, split into chunks, and store in the dictionary\n",
    "for subject_id, group in grouped:\n",
    "    subject_chunks[subject_id] = split_into_chunks(group)\n",
    "\n",
    "# Flatten the dictionary into a DataFrame\n",
    "# Initialize an empty list to hold all chunk records\n",
    "chunk_data = []\n",
    "\n",
    "# Iterate through each subject and their chunks\n",
    "for subject_id, chunks in subject_chunks.items():\n",
    "    for index, chunk in enumerate(chunks):\n",
    "        chunk_data.append({\n",
    "            'subject_id': subject_id,\n",
    "            'chunk_id': index,\n",
    "            'ecg': chunk['ecg'],\n",
    "            'resp': chunk['resp']\n",
    "        })\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "chunks_df = pd.DataFrame(chunk_data)\n",
    "\n",
    "# Print the DataFrame structure\n",
    "print(chunks_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_df = chunks_df[chunks_df['resp'].apply(len) == 7500]\n",
    "chunks_df = chunks_df[chunks_df['ecg'].apply(len) == 7500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-define new columns for calculated metrics\n",
    "chunks_df['Mean Respiration Rate'] = np.nan\n",
    "chunks_df['Total Area Peak to Trough'] = np.nan\n",
    "chunks_df['Total Area Trough to Peak'] = np.nan\n",
    "\n",
    "# List to track indices of rows that cause errors\n",
    "error_indices = []\n",
    "\n",
    "for idx, row in chunks_df.iterrows():\n",
    "    try:\n",
    "        # Try to calculate respiration metrics for the current row\n",
    "        results = calculate_respiration_metrics(row['resp'])\n",
    "        chunks_df.at[idx, 'Mean Respiration Rate'] = results['Mean Respiration Rate']\n",
    "        chunks_df.at[idx, 'Total Area Peak to Trough'] = results['Total Area Peak to Trough']\n",
    "        chunks_df.at[idx, 'Total Area Trough to Peak'] = results['Total Area Trough to Peak']\n",
    "    except Exception as e:\n",
    "        # Log error and mark index for potential removal\n",
    "        print(f\"Error processing row {idx}: {e}\")\n",
    "        error_indices.append(idx)\n",
    "\n",
    "# Optionally, drop rows that caused errors from the DataFrame\n",
    "chunks_df = chunks_df.drop(index=error_indices)\n",
    "\n",
    "# Print updated DataFrame structure or save it to a file\n",
    "print(chunks_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1561b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_df = chunks_df.dropna(subset=['Mean Respiration Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45334af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "# Use legacy Adam optimizer for better compatibility on M1/M2 Macs\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Mean Respiration Rate' is NaN\n",
    "chunks_df = chunks_df.dropna(subset=['Mean Respiration Rate'])\n",
    "\n",
    "# Convert 'ecg' column to a 3D numpy array\n",
    "X = np.array(chunks_df['ecg'].tolist())\n",
    "y = chunks_df['Mean Respiration Rate'].values\n",
    "\n",
    "# Normalize each ECG chunk individually and handle NaNs\n",
    "X_normalized = np.zeros_like(X)\n",
    "for i in range(X.shape[0]):\n",
    "    mean = np.mean(X[i])\n",
    "    std = np.std(X[i])\n",
    "    if std == 0:  # Avoid division by zero\n",
    "        std = 1\n",
    "    X_normalized[i] = (X[i] - mean) / std\n",
    "\n",
    "# Identify rows with NaNs in the normalized data\n",
    "nan_rows = np.isnan(X_normalized).any(axis=1)\n",
    "\n",
    "# Remove rows with NaNs\n",
    "X_normalized = X_normalized[~nan_rows]\n",
    "y = y[~nan_rows]\n",
    "cleaned_chunks_df = chunks_df[~nan_rows]\n",
    "# Check again for NaN values in normalized data\n",
    "print(f\"NaN in X_normalized after cleaning: {np.isnan(X_normalized).sum()}, Inf in X_normalized: {np.isinf(X_normalized).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab091ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 2.5th and 97.5th percentiles\n",
    "lower_percentile = np.percentile(y, 0.5)\n",
    "upper_percentile = np.percentile(y, 99.5)\n",
    "\n",
    "# Clip the values in y_train\n",
    "y = np.clip(y, lower_percentile, upper_percentile)\n",
    "\n",
    "# Verify the clipping\n",
    "print(f\"1th percentile: {lower_percentile}\")\n",
    "print(f\"99th percentile: {upper_percentile}\")\n",
    "print(f\"Before clipping: min = {y.min()}, max = {y.max()}\")\n",
    "print(f\"After clipping: min = {y.min()}, max = {y.max()}\")\n",
    "\n",
    "# Continue with training the model using y_train_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe553333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data by subjects\n",
    "subjects = cleaned_chunks_df['subject_id'].unique()\n",
    "\n",
    "# First, split subjects into training + validation, and test subjects\n",
    "train_val_subjects, test_subjects = train_test_split(subjects, test_size=0.25, random_state=42)\n",
    "\n",
    "# Now split the training + validation subjects to create a training set and validation set\n",
    "train_subjects, val_subjects = train_test_split(train_val_subjects, test_size=0.15, random_state=42)\n",
    "\n",
    "# Create boolean masks for train, validation, and test subjects\n",
    "train_mask = cleaned_chunks_df['subject_id'].isin(train_subjects)\n",
    "val_mask = cleaned_chunks_df['subject_id'].isin(val_subjects)\n",
    "test_mask = cleaned_chunks_df['subject_id'].isin(test_subjects)\n",
    "\n",
    "# Use these masks to create the actual train, validation, and test datasets\n",
    "train_data = cleaned_chunks_df[train_mask]\n",
    "val_data = cleaned_chunks_df[val_mask]\n",
    "test_data = cleaned_chunks_df[test_mask]\n",
    "\n",
    "# Now you have train, validation, and test datasets based on the subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51219acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the masks to create train, validation, and test sets\n",
    "X_train = X_normalized[train_mask]\n",
    "y_train = y[train_mask]\n",
    "X_val = X_normalized[val_mask]\n",
    "y_val = y[val_mask]\n",
    "X_test = X_normalized[test_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "# Print shapes of the datasets to verify\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first few samples of normalized ECG data in separate subplots\n",
    "num_samples_to_plot = 7  # Number of samples to plot\n",
    "fig, axs = plt.subplots(num_samples_to_plot, 1, figsize=(12, 10))\n",
    "\n",
    "for i in range(num_samples_to_plot):\n",
    "    axs[i].plot(X_normalized[i], label=f'Sample {i}')\n",
    "    axs[i].set_title(f'Normalized ECG Sample {i}')\n",
    "    axs[i].set_xlabel('Time (samples)')\n",
    "    axs[i].set_ylabel('Normalized Amplitude')\n",
    "    axs[i].legend()\n",
    "    axs[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ccdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778dc79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Compile the model with a smaller learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='mean_absolute_error', metrics=['mae'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model with the validation data\n",
    "history = model.fit(X_train, y_train, epochs=25, batch_size=64, validation_data=(X_val, y_val))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model with MSE and MAE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse}\")\n",
    "print(f\"Test MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation MAE values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7eecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, linregress\n",
    "\n",
    "# Calculate the Pearson correlation coefficient\n",
    "correlation, p_value = pearsonr(y_test, y_pred.flatten())\n",
    "print(f\"Pearson Correlation: {correlation}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred.flatten(), alpha=0.6, edgecolors='w', linewidth=0.5, label='Data points')\n",
    "\n",
    "# Calculate the regression line\n",
    "slope, intercept, r_value, p_value, std_err = linregress(y_test, y_pred.flatten())\n",
    "regression_line = slope * y_test + intercept\n",
    "plt.plot(y_test, regression_line, color='red', linewidth=2, label='Regression line')\n",
    "\n",
    "plt.title('Actual vs Predicted Mean Respiration Rates')\n",
    "plt.xlabel('Actual Mean Respiration Rate')\n",
    "plt.ylabel('Predicted Mean Respiration Rate')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Add text box with correlation and p-value\n",
    "textstr = f'Pearson Correlation: {correlation:.2f}\\nP-value: {p_value:.2e}'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.gca().text(0.25, 0.95, textstr, transform=plt.gca().transAxes, fontsize=14,\n",
    "               verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd33af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the predicted mean respiration rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y_pred, bins=30, edgecolor='black')\n",
    "plt.title('Histogram of Predicted Mean Respiration Rates')\n",
    "plt.xlabel('Predicted Mean Respiration Rate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4238a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Shuffle and select a few examples from the test set\n",
    "num_examples_to_plot = 5\n",
    "indices = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "selected_indices = indices[:num_examples_to_plot]\n",
    "\n",
    "# Plot the selected examples from the test set\n",
    "fig, axs = plt.subplots(num_examples_to_plot, 1, figsize=(12, 15))\n",
    "\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    axs[i].plot(X_test[idx].flatten(), label='ECG Signal')\n",
    "    axs[i].set_title(f'ECG Signal - Test Sample {idx}')\n",
    "    axs[i].set_xlabel('Time (samples)')\n",
    "    axs[i].set_ylabel('Normalized Amplitude')\n",
    "    axs[i].legend(loc='upper right')\n",
    "    axs[i].text(0.5, 0.95, f'Actual Mean Respiration Rate: {y_test[idx]:.2f}', horizontalalignment='center', verticalalignment='center', transform=axs[i].transAxes)\n",
    "    axs[i].text(0.5, 0.85, f'Predicted Mean Respiration Rate: {y_pred[idx][0]:.2f}', horizontalalignment='center', verticalalignment='center', transform=axs[i].transAxes)\n",
    "    axs[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
